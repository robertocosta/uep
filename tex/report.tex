\documentclass[italian, a4paper, 12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}

\usepackage[left=25mm, top=20mm, right=25mm, bottom=20mm]{geometry}
\renewcommand{\baselinestretch}{1.5}

\usepackage{float}

%%% font & looks %%%
\usepackage{mathpazo}
%\usepackage{palatino}
%\usepackage{kpfonts}
%\usepackage{times}
%\usepackage{charter}
%\usepackage{utopia}

% list of fonts available here - http://www.tug.dk/FontCatalogue/
% and here - https://www.sharelatex.com/learn/Font_typefaces

\usepackage{microtype}

\usepackage[parfill]{parskip}

\usepackage{bm}
\usepackage[labelfont=bf,font={small,it}]{caption}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}

\usepackage{newtxtext}
\usepackage{newtxmath}

%%% boxes %%%
\usepackage{framed}
%\setlength\FrameSep{0.5em}

% math
%\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage{wasysym}
%\usepackage{siunitx}

% graphics
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{pgfplots}
  \pgfplotsset{compat=newest}
  %% the following commands are needed for some matlab2tikz features
  \usetikzlibrary{plotmarks}
  \usetikzlibrary{arrows.meta}
  \usepgfplotslibrary{patchplots}
  \usepackage{grffile}
  \usepackage{amsmath}

\usepackage{pdfpages}

% extra
\usepackage{todonotes} %\todo{ note } , \listoftodos
\usepackage{blindtext}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations.pathreplacing,angles,quotes}
\usepackage{chemformula}
\usepackage{textcomp}
\usepackage{subcaption}

% better tables
\usepackage{booktabs}

%%% links %%%
\usepackage{hyperref}
\hypersetup{
        linktocpage,
        colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\usepackage[framed,numbered]{matlab-prettifier}
\tikzset{
  font={\fontsize{9pt}{12}\selectfont}}

\usepackage{biblatex}
\addbibresource{report.bib}

%%% references %%%
\usepackage[noabbrev,capitalize,nameinlink]{cleveref}

% new commands
\newcommand{\horline}{\rule{1\linewidth}{0.9pt}}
\newcommand{\curl}{\nabla \times}
\renewcommand{\div}{\nabla \cdot}
\newcommand{\laplac}{\nabla^2}
\newcommand{\grad}{\nabla}

%\usepackage{mathspec}

%\newcommand{\mathbbm}[1]{\text{\usefont{U}{bbm}{m}{n}#1}} % from mathbbm.sty
%\newcommand{\indi}[1]{\operatorname{\mathbbm{1}}\left[#1\right]}
\newcommand{\mathbbm}[1]{\text{\usefont{U}{bbm}{m}{n}#1}} % from mathbbm.sty

\newcommand{\E}[1]{\operatorname{E}\left[#1\right]}
\newcommand{\EnB}{\E{\#_B}}

\newtheorem{p}{\\[5mm] \large Problem}
\newenvironment{s}{%\small%
        \begin{trivlist} \item \textbf{Solution}. }{%
\end{trivlist}}%
\begin{document}
\begin{center}
        %\horline\\
        \Large Wireless Systems And Networks\\
        \huge \textbf{Project: Unequal Error Protection}\\[3mm]
        \begin{framed}
                \Large \textbf{Workgroup} \\[2mm]
                \normalsize \textbf{Costa} Roberto -- \textbf{Zanol} Riccardo
        \end{framed}
        %\horline
\end{center}
\FloatBarrier
% Total max 15 pages
\section*{Sommario} % Max 10 lines
La tesina si prefigge di implementare un protocollo per trasmettere flussi video attraverso una rete non completamente affidabile, utilizzando un codice di correzione degli errori a fontana, il quale regola la ridondanza aggiunta ai dati in base alla loro importanza e in base alle necessità di ritrasmissione dei ricevitori.
Verrà analizzata la correttezza della trasmissione (in termini di Bit Error Rate) al variare della Bit Error Rate del canale. Verranno inoltre analizzate la complessità computazionale di codifica e decodifica e il tempo ad esse associato, al variare della ridondanza aggiunta.\\
Il progetto è stato realizzato usando C++ e Python.
\newpage
\section{Introduzione} % Max 1 page
Spesso, al giorno d'oggi, la qualità delle connessioni tra i dispositivi di una rete è variabile, anche, ad esempio, a causa di meccanismi di condivisione di risorse adattativi, finalizzati al rispetto di vincoli variabili di throughput per un numero variabile di utenti. Variabile è anche l'insieme di dispositivi connessi alla rete e il link budget di ogni dispositivo. Quando è necessario trasmettere un flusso video a un insieme di utenti, la qualità del video, in questo tipo di rete, dev'essere necessariamente variabile in base alla banda disponibile ad ogni utente. Un protocollo che si presta al multicast video attraverso connessioni eterogenee è l'estensione Scalable Video Coding (SVC) del protocollo H.264/MPEG-4 AVC \cite{svc}. Tale protocollo, infatti, permette di codificare il video una sola volta per tutti gli utenti, separando il file originale in un numero arbitrario di stream, la cui composizione garantisce alta fedeltà di ricostruzione del flusso video originale, ma non è indispensabile avere tutti le componenti per ricostruire un video a qualità inferiore.\\
Per trasmettere un flusso di dati attraverso un canale variabile e non completamente affidabile, garantendo la qualità del servizio, è utile aggiungere ridondanza all'informazione inviata. Il rapporto tra il messaggio con ridondanza aggiunta e il messaggio originale è chiamato rate del codice di correzione degli errori.
I codici a fontana \cite{fcsurvey, rossifc} presentano due caratteristiche notevoli, rispetto ad altri codici di correzione degli errori:
\begin{itemize}
\item Bassa complessità computazionale per la codifica e per la decodifica
\item Assenza di un code rate fisso.
\end{itemize}
I codici a fontana possono essere usati per proteggere allo stesso modo tutti i dati da trasmettere, caso in cui la ridondanza aggiunta dipende solo dalle condizioni del canale (EEP, equal error protection), oppure si possono proteggere maggiormente i dati più sensibili (UEP, unequal error protection \cite{uep}), caso in cui la ridondanza aggiunta dipende anche dall'importanza del dato.\\
Il vantaggio dato dalla possibilità di aggiungere una quantità arbitraria di ridondanza, oltre che nel proteggere meglio i dati più sensibili, risiede anche nella possibilità di sfruttare un canale che ha un comportamento variabile nel tempo e ignoto a priori: la quantità di ridondanza aggiunta può crescere al peggiorare delle condizioni del canale, a differenza di un codice a rate fisso che comporta uno spreco di banda se il canale è in buone condizioni, o insufficiente protezione se il canale non è in buone condizioni.
\section{Approccio tecnico}
\subsection{Obbiettivi} % Max 5 lines
La finalità del progetto è estendere il paper \cite{uep}, in cui è proposto un algoritmo per l'UEP basato sui codici a fontana, testando l'algoritmo di trasmissione con protezione non uniforme nel caso di un canale che introduce errori.
%
Considerando sia il caso di errori indipendenti che il caso di errori correlati, questo progetto vuole dimostrare che il protocollo di protezione non uniforme è utile ed efficiente anche in condizioni non error-free.
\subsection{Scenario} % Max 20 lines
Lo scenario considerato rappresentato in figura~\ref{fig:UDP}. Un
server trasmette un video H264 a un client segmentandolo in pacchetti
di lunghezza costante e divisi in due classi di priorità. I pacchetti
sono aggregati in blocchi con una struttura fissata (cioè contengono
sempre lo stesso numero di pacchetti per ogni classe di priorità). I
blocchi sono poi codificati utilizzando l'algoritmo proposto in
\cite{uep}, a un livello di overhead fissato e inviati dentro
pacchetti UDP al client.
%\includegraphics[trim=0cm 8cm 0cm 7cm, width=1.00\textwidth]{TCP.pdf}
%\includegraphics[width=180mm]{UDP.pdf}
%\includepdf[pages={1}]{UDP.pdf}
%\begin{figure}[htbp]
\begin{figure}[H]
    \centering
        \includegraphics[clip, trim=0cm 1cm 0cm 1cm, width=1.00\textwidth]{UDP.pdf}
    \caption{Video stream encoding / decoding and transmission}
    \label{fig:UDP}
\end{figure}
\begin{figure}[H]
    \centering
        \includegraphics[clip, trim=0cm 1cm 0cm 1cm, width=1.00\textwidth]{TCP.pdf}
    \caption{TCP connection and tansmission setup}
    \label{fig:TCP}
\end{figure}
%\includepdf{TCP.pdf}
\newpage
\subsection{Modelli matematici}
\subsubsection{Canale}
\label{sec:markov}
Il canale è rappresentato da una catena di Markov a 2 stati: buono (G) e cattivo (B).\\
Lo stato del sistema all'indice temporale $n$ (slot $n$) è indicato con $X(n)$, o $X_n$.\\
Sono stati effettuati test con due tipi di canale:
\begin{itemize}
\item Canale Markoviano, caratterizzato dalla seguente matrice di probabilità di transizione:\\
$$P=\begin{pmatrix}
P[X_n=G, X_{n+1}=G] & P[X_n=G, X_{n+1}=B]\\
P[X_n=B, X_{n+1}=G] & P[X_n=B, X_{n+1}=B]\\
\end{pmatrix} = \begin{pmatrix}
P_{GG} & P_{GB} \\
P_{BG} & P_{BB}
\end{pmatrix} =
\begin{pmatrix}
1-p & p \\
q & 1-q
\end{pmatrix}$$
Le probabilità stazionarie sono definite come
$$\bm{\pi} = \begin{pmatrix}
\pi_G\\\pi_B
\end{pmatrix} = \lim_{n \to\infty} \begin{pmatrix}
P[X(n)=G]\\
P[X(n)=B]
\end{pmatrix}$$
e possono essere ricavate dall'equazione
$$P^T\cdot \bm{\pi} = \bm{\pi} \Leftrightarrow \begin{pmatrix}
\pi_G\\
\pi_B
\end{pmatrix}=
\begin{pmatrix}
\frac{q}{p+q}\\
\frac{p}{p+q}
\end{pmatrix}$$
La probabilità stazionaria che il canale sia nello stato B è la probabilità d'errore media:
$$E[P_e] = \pi_B$$
Può essere definita la variabile aleatoria $\#_B$ che indica il numero di slot in cui il sistema resta nello stato B, la cui distribuzione di probabilità può essere scritta come:
$$P[\#_B=k]= \left(P_{BB}\right)^{k-1}P_{BG} = (1-q)^{k-1} q$$
Il valore atteso di $\#_B$ è l'inverso della probabilità di transizione da B a G:
$$E[\#_B] = \sum_{k=0}^{+\infty} k \cdot (1-q)^{k-1} q = q \cdot \frac{1}{(1-(1-q))^2} = \frac{1}{q}$$
I parametri impostati per il canale simulato sono stati il numero medio di slot B consecutivi, $E[\#_B]$, e la probabilità d'errore media $\pi_B$. In seguito sono state ricavate le seguenti quantità:
\begin{equation}
  \begin{cases}q = \frac{1}{\EnB}\\
\pi_G = 1- \pi_B\\
p = q\frac{\pi_B}{\pi_G}\end{cases}
  \label{eq:mcparams}
\end{equation}
Il numero medio di iterazioni necessarie a sbagliare N pacchetti è, in media,
$$E[\theta_{0N}] = \frac{\pi_G}{p} + \frac{N-1}{\pi_B}$$
Un altro tipo di canale markoviano testato è stato mantenendo fissa la quanità $\EnB$ e facendo variare la probabilità d'errore $\pi_B$.
\item Canale senza memoria, con packet error rate fisso $P_e$
\end{itemize}
Di seguito la rappresentazione Markoviana.
\begin{figure}[H]
    \centering
        \includegraphics[clip, trim=0cm 1cm 0cm 1cm, width=0.5\textwidth]{Channel.pdf}
    \caption{Rappresentazione Markoviana dei due tipi di canale analizzati}
    \label{fig:Channel}
\end{figure}
\subsubsection{Codici a fontana}\label{FCsection}
I codici a fontana sono una classe di codici di correzione degli errori che aggiunge a un messaggio $\bm{x}\in\mathcal{A}^K$, di lunghezza $K$, una quantità di ridondanza potenzialmente infinita, aumentando la lunghezza del messaggio codificato $\bm{y}\in\mathcal{A}^N$, in modo tale che sia possibile recuperare il messaggio originale da un sottoinsieme di cardinalità leggermente maggiore di $K$ (e minore di $N$) del messaggio codificato.\\
%L'overhead introdotto dalla codifica è dato da $t = \frac{N-K}{K}$.\\
Fissando la lunghezza del messaggio codificato, $N$, per ogni messaggio originale di lunghezza $K<N$, è possibile schematizzare la codifica di canale lineare attraverso la seguente equazione
\begin{equation}
\bm{y} =
\begin{pmatrix}
y_1 \\y_2 \\y_3 \\\vdots \\y_N
\end{pmatrix} = \underbrace{\begin{pmatrix}
g_{11}	&g_{12}	&\cdots	&g_{1K}\\
g_{21}	&g_{22}	&\cdots	&g_{2K}\\
g_{31}	&g_{32}	&\cdots	&g_{3K}\\
\vdots &\ddots & \ddots &\vdots\\
g_{N1}	&g_{N2}	&\cdots	&g_{NK}
\end{pmatrix}}_{=G} \begin{pmatrix}
x_1 \\x_2 \\\vdots \\x_K
\end{pmatrix} = G \cdot \bm{x}
\end{equation}
dove $G$ è la matrice di codifica, $g_{ij}\in\{0,1\}$, $x_i\in\mathcal{X}$, $y_i\in\mathcal{Y}$.\\
La $i-$esima riga della matrice $G$ è casuale e il suo grado (la distanza di hamming dall'origine) segue una distribuzione di probabilità nota: la Robust Soliton Distribution.\\
La codifica dell'$i-$esimo pacchetto avviene attraverso l'operazione di \textit{OR esclusivo} tra i pacchetti di informazione indicati dalla $i-$esima riga di $G$.\\
Se $G$ è invertibile, è possibile recuperare il vettore $\bm{x}$ da $\bm{y}$ attraverso la risoluzione di un sistema lineare.\\
I codici a fontana non prevedono la risoluzione di un sistema lineare per la decodifica, bensì un algoritmo di \textit{message passing}: con riferimento alla figura (\ref{fig:FC})
\begin{itemize}
        \item SE esiste un simbolo codificato $e_n$ con un solo arco entrante (come $e_4$)\begin{itemize}
                \item	Decodifica il simbolo di informazione corrispondente $i_k=e_n$ ($i_5$ in questo caso)
                \item	Rimpiazza tutti i simboli codificati $e_{n'}$ aventi un arco entrante da $i_k$ con $e_{n'}^{\text{new}} = e_{n'} \textit{ XOR } i_k$
                \item   Rimuove gli archi da $i_k$
                \item   SE ci sono altri simboli di informazione da decodificare \begin{itemize}
                        \item Torna all'inizio
                \end{itemize}
                \item ALTRIMENTI\begin{itemize}
                        \item Decodifica riuscita
                \end{itemize}
        \end{itemize}

        \item ALTRIMENTI Decodifica fallita
\end{itemize}
\begin{figure}[H]
    \centering
        \makebox[\textwidth][c]{\includegraphics[width=6cm]{fc.png}}
    \caption{Schema: \textit{message passing}}
    \label{fig:FC}
\end{figure}
\newpage
\subsubsection{H.264}
Più nel dettaglio, il flusso video codificato è organizzato in unità NAL (Network Abstraction Layer) che possono essere di 2 tipi: VCL NAL Packets (Video Coding Layer) e non-VCL NAL packets. I pacchetti non-VCL possono contenere il set di parametri da usare per decodificare (informazioni necessarie per la decodifica, quindi ad alta priorità), oppure delle informazioni supplementari per migliorare la decodifica (SEI, Supplemental Enhancement Information). Il bitstream NAL è composto da una serie di sequenze video più corte (GOP, Group Of Pictures) decodificabili indipendentemente dal resto del flusso: ogni GOP comincia con tutte le informazioni necessarie alla decodifica, in modo che essa possa avvenire anche senza aver decodificato nessun segmento precedente.\\
Un tipo di applicazione che si presta particolarmente all'utilizzo di UEP \cite{uep} è lo streaming di un video codificato attraverso SVC, infatti tale protocollo rende possibile la decodifica di un flusso video da flussi parziali, chiamati \textit{layer}, con risoluzione spaziale o temporale minore, o con fedeltà ridotta. I layer sono ordinati dal più importante (layer 0, a bassa qualità) al meno importante (layer \textit{n}, che permette di raggiungere alta qualità).\\
La presenza di informazioni più rilevanti di altre (come i parametri per la decodifica e i layer inferiori, in particolare i frame intra-coded) giustifica l'uso di UEP: i flussi con priorità minore aggiungono qualità al video decodificato, ma non sono indispensabili per la decodifica, quindi possono essere protetti con meno ridondanza.
\subsubsection{UEP}\label{UEPsection}
La protezione non uniforme di un messaggio prevede la divisione dello stesso in $p$ parti di diversa importanza.\\
Ogni parte viene ripetuta un numero $RF_i$ di volte, con $i\in\{1,\cdots,p\}$, in base alla sua importanza.\\
Il risultato della giustapposizione delle parti ripetute viene a sua volta ripetuto un numero $EF$ di volte.\\
Il messaggio che si ottiene da tali giustapposizioni è mappato nelle parti originali del messaggio originale e viene inviato al codificatore a fontana. Di seguito uno schema rappresentativo con $p=2$, $RF_1 = 2$,$RF_2=1$, $EF=2$.
\begin{figure}[H]
    \centering
        \makebox[\textwidth][c]{\includegraphics[width=8cm]{uep.png}}
    \caption{Schema della protezione non uniforme}
    \label{fig:UEP}
\end{figure}
\newpage
\subsection{Complicazioni trovate} % Max 5 lines

\section{Risultati} % Min 7 pages
L'algoritmo per la protezione non uniforme esposto nel
paragrafo~\ref{UEPsection} è stato testato nei due casi di canale
senza memoria e di canale Markoviano per determinare la packet error
rate ottenibile in queste due condizioni.

Sono stati inoltre misurati i tempi necessari alla codifica e
decodifica dei pacchetti in funzione dell'overhead desiderato.

Purtroppo l'esecuzione dell'intera implementazione dello schema di
figura~\ref{fig:UDP} richiede un tempo tale da rendere difficoltosa la
costruzione di grafici che siano precisi per PER basse.
%
I risultati dei paragrafi seguenti sono, quindi, stati ottenuti
utilizzando solamente l'implementazione del message passing, senza
trasmettere realmente dei pacchetti.

\subsection{Packet error rate su un canale senza memoria}
In questo caso è stata misurata la packet error rate a livello di
applicazione ottenuta variando l'overhead e considerando diversi
valori per la packet error rate del canale.
%
Facendo riferimento alla figura~\ref{fig:UDP}, la PER di livello
applicazione è misurata come la frazione di pacchetti forniti all'UEP
encoder che raggiungono l'uscita dell'UEP decoder.
%
L'overhead è definito, in modo analogo a \cite{uep}, come $t =
\frac{N-K}{K}$, cioè come l'aumento relativo del numero di pacchetti
trasmessi dovuto alla codifica.

Per permettere l'esecuzione di un gran numero di test, l'encoder e il
decoder sono stati eseguiti sullo stesso computer, senza inviare
pacchetti UDP e simulando un canale senza memoria che scarta i
pacchetti con una data probabilità $e$.
%
Per lo stesso motivo è stata utilizzata in questo paragrafo una
sorgente di pacchetti generati casualmente invece di segmentare
realmente un video H264.

Sono stati usati gli stessi valori per i parametri specificati da
\cite{uep} per permettere un confronto con i risultati ottenuti in
questa tesina e di verificare la correttezza dell'implementazione.
%
I pacchetti in ingresso sono aggregati in blocchi di $K_0 = 100$
pacchetti importanti e $K_1 = 900$ pacchetti non importanti; il blocco
virtuale è stato costruito ripetendo $RF_0 = 3$ volte il primo
sotto-blocco, $RF_1 = 1$ volte il secondo ed espandendo la sequenza di
pacchetti così ottenuta di un fattore $EF = 4$. La lunghezza del
blocco virtuale è quindi pari a $EF \cdot \left( RF_0 \cdot K_0 + RF_1
\cdot K_1 \right) = 4800$ pacchetti.
%
L'overhead è stato fatto variare nell'intervallo $[0, 0.8]$, a cui
corrisponde un numero di pacchetti inviati $N \in [1000, 1800]$ per
ogni blocco di $K=K_0+K_1$ pacchetti.
%
La probabilità di errore del canale è stata impostata ai valori
$e \in \left\{ 0, 10^{-2}, 10^{-1}, 2 \cdot 10^{-1} \right\}$.

In figura~\ref{fig:iid} sono mostrati i risultati della simulazione di
una trasmissione di 10000 blocchi.
%
\begin{figure}[H]
    \centering
        \includegraphics[clip, trim=0cm 0cm 0cm 0cm, width=0.80\textwidth]{plot_ber_iid.pdf}
    \caption{Packet error rate misurata su un canale iid al variare
    dell'overhead}
    \label{fig:iid}
\end{figure}
%
Come è possibile osservare, le curve corrispondenti al canale senza
errori ($e=0$) sono coerenti con \cite{uep} fino a una PER di
$10^{-3}$, infatti in corrispondenza di un overhead del 25\% la PER
della parte più importante scende sotto $10^-3$ come nel paper

: la probabilità di errore
scende sotto $10^{-3}$ con un over

. Negli altri tre casi, invece, la PER segue lo
stesso andamento del caso senza errori ed è semplicemente traslata
verso destra di una lunghezza pari alla PER del canale.
%
Si può infatti notare come nel caso $e = 10^{-2}$ l'algoritmo testato
abbia delle prestazioni molto vicine a quelle ottenibili su un canale
senza errori, mentre nei casi con PER $e = 10^{-1}$ ed $e = 3\cdot
10^{-1}$ le curve siano traslate, rispettivamente, di $0.1$ e $0.3$
rispetto al caso senza errori.

\subsection{Packet error rate su un canale Markoviano}
Nel caso del canale Markoviano, descritto nel
paragrafo~\ref{sec:markov}, sono state eseguite simulazioni per
valutare la packet error rate variando la lunghezza media $E[\#_B]$
di una sequenza di slot cattivi consecutivi e considerando diversi
valori per la dimensione del blocco $K$.
%
Come per il paragrafo precedente, qui sono stati usati un canale
simulato e una sorgente di pacchetti casuali per permettere
l'esecuzione di test con un gran numero di pacchetti.
%
La frazione di pacchetti importanti presente in ogni blocco è stata
mantenuta al 10 \%, come per il caso iid, e anche per gli altri
parametri ($RF_0$, $RF_1$, $EF$ e $L$) sono stati usati gli stessi
valori dei test precedenti.
%
Il numero di pacchetti trasmessi $N$ è stato fissato per avere un
overhead del 25 \%, mentre la probabilità stazionaria di errore del
canale è stata fissata a $\pi_B = 10^{-3}$. Da quest'ultima e da
$\EnB$ sono state ricavate le probabilità di transizione secondo
\eqref{eq:mcparams}.

Variando le dimensioni di blocco $K \in [10, 6000]$ e considerando tre
diversi canali Markoviani, corrispondenti a $E[\#_B] \in \{10, 100,
500\}$ sono stati ottenuti i risultati mostrati in
figura~\ref{fig:markov}.
%
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.8\textwidth]{plot_markov}
  \caption{Packet error rate a livello applicazione ottenuta al
    variare della dimensione del blocco su tre canali Markoviani.}
  \label{fig:markov}
\end{figure}

Osservando le tre coppie di curve è possibile notare come il loro
andamento sia pressoché identico per valori di $K$ bassi e come, per
blocchi di dimensione così piccola, la probabilità di errore sia molto
superiore a quella del canale.
%
Questo è dovuto alle scarse prestazioni in termini di probabilità di
decodifica dei codici LT quando sono usati per codificare blocchi
troppo piccoli.
%
Infatti è possibile vedere in figura~\ref{fig:noerrk} la probabilità di
decodifica al variare della dimensione del blocco su un canale senza
errori, usando gli stessi parametri dei tre casi Markoviani.
%
\begin{figure}[htb]
  \centering
  %\includegraphics[width=0.8\textwidth]{plot_noerr_k}
  \caption{Packet error rate a livello di applicazione al variare
    della dimensione del blocco su un canale senza errori. I parametri
    usati sono gli stessi di figura~\ref{fig:markov}.}
  \label{fig:noerrk}
\end{figure}

Quando la dimensione del blocco diventa grande abbastanza ($K \approx
1500$), invece, si può notare un diverso comportamento a seconda della
correlazione degli errori del canale.
%
Nel caso $\EnB = 500$ entrambe le packet error rate del MIB e del LIB
rimangono intorno a $10^{-3}$ su tutto l'intervallo di $K$
considerato. Nel caso $\EnB = 100$ è possibile vedere che il MIB e il
LIB subiscono delle packet error rate diverse e tendono a
decrescere. Infine, anche nel caso $\EnB = 10$ è visibile la diversa
PER per il MIB e il LIB, ma adesso entrambi hanno un salto in
corrispondenza di $K \approx 2300$ e poi decrescono più lentamente del
caso $\EnB = 100$.

Da tutto ciò possiamo vedere come, nel caso di errori correlati,
l'effetto della protezione non uniforme sia quasi inesistente per
valori di $K$ piccoli, infatti sia MIB che LIB subiscono la stessa
probabilità di errore. Al crescere di $K$, invece, è possibile
applicare la protezione non uniforme.
%
Questo effetto è l'opposto di quanto accade nel caso IID \cite{uep}
dove, al crescere della dimensione del blocco, le probabilità di
errore su MIB e LIB tendono ad avvicinarsi.

Si vede anche come la correlazione tra gli errori provochi un notevole
peggioramento delle prestazioni rispetto al caso IID: anche con il
valore più piccolo per la lunghezza media di una sequenza di slot
cattivi ($\EnB = 10$) è necessario un blocco di $K\approx 2300$ per
ottenere una PER a livello applicazione simile a quanto è possibile
ottenere nel caso IID con $e=10^{-3}$ per $K=1000$, usando lo stesso
overhead (25\%).

Visto l'alto valore della PER per canali con alto numero di errori correlati,
sono stati simulati altri 2 canali con $\pi_B \in\{10^{-3}, 10^{-2}, 10^{-1}\}$
mantenendo fisso $\EnB=10$.\\
\begin{figure}[H]
    \centering
        %\makebox[\textwidth][c]{\includegraphics[width=0.8\textwidth]{local_markov_plot_.png}}
    \caption{Packet error rate a livello di applicazione al variare
    della PER, con $\EnB = 10$. I parametri
    usati sono gli stessi di figura~\ref{fig:markov}.}
  \label{fig:enbfixed}
\end{figure}
Il numero medio di slot buoni consecutivi, nei 3 casi, è $E[\#_G]\in\{9990,990,90\}$.\\
Dal grafico si nota che l'effetto della protezione non uniforme, calcolato come il rapporto
tra la PER della parte meno importante e la PER della parte più importante, è maggiore
quando la probabilità d'errore stazionaria ($\pi_B$) aumenta.

\subsection{Scelta della dimensione dei pacchetti}
\label{sec:pktsize}
Il paper \cite{uep} considera simboli di 1 byte durante la codifica,
ma questa scelta non è praticabile nel caso di questa tesina. Il
motivo è dato dall'overhead introdotto aggiungendo degli header a ogni
pacchetto, infatti una dimensione di pacchetto $L=1$ comporterebbe un
overhead del 1500 \% dovuto solo agli header.

Questo overhead decresce all'aumentare della dimensione dei pacchetti
$L$, tuttavia bisogna considerare l'overhead introdotto dalla
segmentazione del video H264.
%
Il video H264 è composto da pacchetti (detti NALU) di dimensioni
variabili che devono essere aggregati o segmentati in pacchetti di
dimensione fissa $L$. Il fatto di considerare due diverse classi di
priorità per le NALU richiede di inserire un certo numero di byte di
padding, ogni volta che termina una sequenza consecutiva di NALU con
la stessa priorità, per ottenere un numero intero di pacchetti di
lunghezza $L$.

Tenendo conto di entrambi questi contributi all'overhead si ottiene il
grafico mostrato in figura~\ref{fig:pktsize} ed è possibile
individuare il valore $L = 388$ che minimizza l'overhead dovuto al
padding e agli header.
% Best packet size = 388
% Min overhead = 0.069367
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{plot_overhead}
  \caption{Overhead introdotto dalla segmentazione al variare della
    dimensione $L$ dei pacchetti.}
  \label{fig:pktsize}
\end{figure}

\subsection{Tempi di codifica e decodifica}
Per verificare quanto tempo è necessario alla codifica e alla
decodifica di un blocco di pacchetti al variare dei parametri è stata
simulata la trasmissione di 500 blocchi al variare dell'overhead,
utilizzando lo stesso procedimento dei paragrafi precendenti.

Sono stati simulati sia il caso di equal error protection che quello
di unequal error protection, usando diversi valori per il fattore di
espansione $EF \in \{ 1,2,4 \}$. Gli altri parametri sono gli stessi
dei paragrafi precedenti: $K = 2000$, $K_0 = K \cdot 0.05$, $c=0.1$,
$\delta=0.5$ e per il caso UEP $RF_0 = 5$.

In figura~\ref{fig:encdec} sono mostrati i tempi medi di codifica e di
decodifica ottenuti eseguendo le simulazioni su una CPU Intel Xeon
E5450 con 16 GB di RAM.
%
\begin{figure}[htb]
  \centering
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plot_enc_time_eep}
    \caption{Codifica EEP}
    \label{fig:enctime_eep}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plot_dec_time_eep}
    \caption{Decodifica EEP}
    \label{fig:dectime_eep}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plot_enc_time_uep}
    \caption{Codifica UEP}
    \label{fig:enctime_uep}
  \end{subfigure}%
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{plot_dec_time_uep}
    \caption{Decodifica UEP}
    \label{fig:dectime_uep}
  \end{subfigure}
  \caption{Tempi medi di codifica e decodifica per un blocco di
    $K=2000$ pacchetti codificato usando EEP o UEP ($K_0 = 100$,
    $RF_0=5$) con $EF \in \{1,2,4\}$.}
  \label{fig:encdec}
\end{figure}
%
Si può vedere che l'andamento è coerente con \cite{uep}: i tempi di
codifica aumentano linearmente al crescere del'overhead e
sub-linearmente al crescere di $EF$; i tempi di decodifica crescono
velocemente fino al livello di overhead in cui la maggior parte dei
pacchetti sono decodificati e, in seguito, la crescita diventa molto
più lenta.
%
I valori dei tempi di decodifica sono dello stesso ordine di grandezza
di quelli riportati in \cite{uep}, mentre i valori dei tempi di
codifica sono molto più alti, sia dell'articolo che dei tempi di
decodifica corrisponenti. Questo può essere spiegato dal fatto che,
mentre l'implementazione del message passing usata nelle simulazioni è
scritta in C++, la generazione dei vettori di codifica è effettuata da
uno script scritto in Python.

\newpage
\section{Conclusioni} % Max 0.5 pages


%\begin{figure}[H]
%	\makebox[\textwidth][c]{\includegraphics[width=16cm]{G10labE_f3.eps}}
%	\caption{Componenti di $\hat{s}$}\label{fig:s2}
%\end{figure}

% Between 3-15 refs
\printbibliography[heading=bibnumbered, title=Bibliografia]
\end{document}
